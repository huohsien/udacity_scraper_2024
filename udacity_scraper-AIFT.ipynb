{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_message = \"Press Enter to naviagte to: \"\n",
    "prompt_message = None\n",
    "DELAY_SECONDS_CONTENT_LOADING = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPLICIT_DELAY = 60\n",
    "EXPLICIT_DELAY = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup option for chrome profile\n",
    "chrome_options = Options()\n",
    "\n",
    "## NEVER USE THE FOLLOWING OPTION SINCE IT WILL MAKE SUPPOSEDLY DIFFERENT WINDOWS FOR DIFFERENT CLASS MIXED IN SOME WAY!!!!\n",
    "# chrome_options.add_argument(\"user-data-dir=/Users/huohsien/Library/Application Support/Google/Chrome/Default/\")\n",
    "## the following option is to solve the error if using the above cause a problem\n",
    "# chrome_options.add_argument(\"--remote-debugging-port=9222\") \n",
    "\n",
    "prefs = {'profile.default_content_setting_values.automatic_downloads': 1}\n",
    "chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "\n",
    "\n",
    "#start web driver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.implicitly_wait(IMPLICIT_DELAY)\n",
    "wait = WebDriverWait(driver, EXPLICIT_DELAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException        \n",
    "def check_exists_by_xpath(driver, xpath):\n",
    "    try:\n",
    "        driver.find_element(\"xpath\",xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def sync_get_element_by_xpath(driver, wait, xpath):\n",
    "\n",
    "    try:\n",
    "        wait.until(ec.presence_of_element_located((By.XPATH, xpath)))\n",
    "    except TimeoutException:\n",
    "#         print(\"Get element from xpath:{} Timeout\".format(xpath))\n",
    "        return None\n",
    "    return driver.find_element(\"xpath\",xpath)\n",
    "\n",
    "def sync_get_elements_by_xpath(driver, wait, xpath):\n",
    "\n",
    "    try:\n",
    "        wait.until(ec.presence_of_all_elements_located((By.XPATH, xpath)))\n",
    "    except TimeoutException:\n",
    "#         print(\"Get element from xpath:{} Timeout\".format(xpath))\n",
    "        return None\n",
    "    return driver.find_elements(\"xpath\",xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lesson_complete(item)->bool:\n",
    "    e1 = item.find_element_by_xpath(\"./div/div\")\n",
    "    c = e1.get_attribute('class')\n",
    "    if c == 'index--lesson-card--mwX1V index--card--3DZMr shared--card--3X88h':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def expand_all_complete_lessons():\n",
    "    #click open the ones that were marked Complete\n",
    "    lessons = sync_get_elements_by_xpath(\"//div[@data-test='part-syllabus']/ol/li\")\n",
    "    for lesson in lessons:\n",
    "        if check_lesson_complete(lesson):\n",
    "            lesson.click()\n",
    "    element = driver.find_element_by_xpath(\"//*[h3='lesson 1']\")\n",
    "    driver.execute_script(\"return arguments[0].scrollIntoView(true);\", element)\n",
    "#     time.sleep(1)\n",
    "\n",
    "def embed_tag(tag, html_str):\n",
    "    return '<{}>'.format(tag) + html_str + '</{}>'.format(tag)\n",
    "\n",
    "def debug_breakpoint(title, message=None):\n",
    "    if message == None:\n",
    "        print(title)\n",
    "    else:\n",
    "        input(title + ' - ' + message)\n",
    "\n",
    "def write_to_clipboard(output):\n",
    "    process = subprocess.Popen(\n",
    "        'pbcopy', env={'LANG': 'en_US.UTF-8'}, stdin=subprocess.PIPE)\n",
    "    process.communicate(output.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_css_files():\n",
    "    \n",
    "    css_folder_path = os.path.join(root_folder, topic_name,lesson_name, part_name, \"css\")\n",
    "    \n",
    "    if not os.path.exists(css_folder_path):\n",
    "        os.makedirs(css_folder_path)\n",
    "        \n",
    "    html_src = driver.page_source\n",
    "    base = driver.current_url\n",
    "    soup = BeautifulSoup(html_src)\n",
    "    css_link_elms = soup.find_all('link', {'rel': 'stylesheet'})\n",
    "    \n",
    "    css_links = []\n",
    "    for idx, css_link_elm in enumerate(css_link_elms, start = 1):\n",
    "        link = css_link_elm['href']\n",
    "        if link.startswith('/'):\n",
    "            link = urllib.parse.urljoin(base, link)\n",
    "        css_links.append(link)\n",
    "#         print(idx, \": \", link)\n",
    "    \n",
    "    for css_link in css_links:\n",
    "        r = requests.get(css_link, allow_redirects=True)\n",
    "        a = urlparse(css_link)\n",
    "        file_name = os.path.basename(a.path)\n",
    "        file_name = os.path.join(css_folder_path, file_name)\n",
    "#         print(\"file_name= \", file_name) \n",
    "    \n",
    "        open(file_name, 'wb').write(r.content)\n",
    "\n",
    "def make_images_local(soup):\n",
    "    \n",
    "    images_folder = os.path.join(root_folder, topic_name,lesson_name, part_name, \"img\")\n",
    "\n",
    "    img_elms = soup.find_all('img')\n",
    "    for img_elm in img_elms:\n",
    "        img_link = img_elm['src']\n",
    "        r = requests.get(img_link, allow_redirects=True)\n",
    "        a = urlparse(img_link)\n",
    "        file_name = os.path.basename(a.path)                \n",
    "        img_path = \"./\" + images_folder + \"/\" + file_name\n",
    "\n",
    "        if not os.path.exists(images_folder):\n",
    "            os.makedirs(images_folder)\n",
    "\n",
    "        open(img_path, 'wb').write(r.content)\n",
    "#         print(\"file_name: \", file_name)\n",
    "        # replace src in img element\n",
    "        img_elm['src'] = \"./img/{}\".format(file_name)\n",
    "\n",
    "def create_head_str():\n",
    "    \n",
    "    css_folder_path = os.path.join(root_folder, topic_name,lesson_name, part_name, \"css\")\n",
    "    css_filenames = [f for f in os.listdir(css_folder_path) if os.path.isfile(os.path.join(css_folder_path, f))]\n",
    "    \n",
    "    page_html = driver.page_source\n",
    "    page_soup = BeautifulSoup(page_html, 'html.parser')\n",
    "    style_elms = page_soup.find('head').find_all('style')\n",
    "    \n",
    "    meta_elm = '<meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\">'\n",
    "    head_str = '<head>' + meta_elm\n",
    "    for css_filename in css_filenames:\n",
    "        link_str = '<link rel=\"stylesheet\" href=\"./css/{}\">'.format(css_filename)\n",
    "        head_str = head_str + link_str\n",
    "    for style_elm in style_elms:\n",
    "        head_str = head_str + str(style_elm)\n",
    "    \n",
    "    head_str = head_str + '</head>'\n",
    "#     print(\"head_str: \", head_str)\n",
    "    return head_str\n",
    "\n",
    "def process_content_html(content_html_str):\n",
    "    \n",
    "    download_css_files()\n",
    "            \n",
    "    head_str = create_head_str()\n",
    "    body_str = embed_tag('body', content_html_str)\n",
    "    page_html_str = head_str + body_str\n",
    "    html_str = embed_tag('html', page_html_str)\n",
    "    \n",
    "    # remove unwanted div element\n",
    "    soup = BeautifulSoup(html_str, 'html.parser')\n",
    "    div_to_be_remove_class_name = '_main--notification-bar--2AVbT'\n",
    "    to_be_removed_elms = soup.find_all('div',class_=div_to_be_remove_class_name)\n",
    "    for to_be_removed_elm in to_be_removed_elms:\n",
    "        to_be_removed_elm.decompose()\n",
    "    \n",
    "    make_images_local(soup)\n",
    "    \n",
    "    return soup.prettify()\n",
    "\n",
    "def copy_youtube_link_to_clipboard(video_link):\n",
    "    write_to_clipboard(video_link)\n",
    "    time.sleep(1)\n",
    "    \n",
    "def grab_all_youtube_links(content_html_str, download=False):\n",
    "\n",
    "    content_soup = BeautifulSoup(content_html_str, 'html.parser')\n",
    "    youtube_iframe_elms = content_soup.find_all('iframe', {'title': 'YouTube video player'})\n",
    "    video_links = ''\n",
    "    for idx, youtube_iframe_elm in enumerate(youtube_iframe_elms, start=1):\n",
    "        video_link = youtube_iframe_elm['src']\n",
    "        video_link = video_link + '#index={}_{}_{}_{}'.format(topic_name,lesson_name, part_name,idx)\n",
    "        video_links = video_links + video_link + '\\n\\n'\n",
    "        if download == True:\n",
    "            copy_youtube_link_to_clipboard\n",
    "        \n",
    "    #     print(idx, ' : ', video_link)\n",
    "#     print(video_links)\n",
    "    with open('all_youtube_video_links.txt','a') as fp:\n",
    "        fp.writelines(video_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_html():\n",
    "\n",
    "    contents = sync_get_elements_by_xpath(\"//div[@id='content']\")\n",
    "    assert len(contents) == 1\n",
    "\n",
    "    content_html = contents[0].get_attribute('outerHTML')\n",
    "    html_str = process_content_html(content_html)\n",
    "    grab_all_youtube_links(content_html, False)\n",
    "    \n",
    "    file_name = os.path.join(root_folder, topic_name,lesson_name, part_name, \"content.html\")\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(html_str)\n",
    "#     print(\"html_str= \", html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_address = 'https://learn.udacity.com/nanodegrees/nd880/parts/cd0569'\n",
    "root_folder = './ai_for_trading_course_downloaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start\n",
    "driver.get(root_address)\n",
    "os.makedirs(root_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_get_element_by_xpath(driver, wait, \"//div[text()='Sign in']\").click()\n",
    "\n",
    "email = sync_get_element_by_xpath(driver, wait, \"//input[@id='email']\")\n",
    "password = sync_get_element_by_xpath(driver, wait, \"//input[@id='revealable-password']\")\n",
    "\n",
    "email.send_keys(\"huohsien@gmail.com\")\n",
    "password.send_keys(\"Huo18941256\")\n",
    "\n",
    "sync_get_element_by_xpath(driver, wait, \"//div[@data-testid='signin-form']//span[text()='Sign in']/..\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sign_in():\n",
    "#     email = sync_get_element_by_xpath(\"//input[@data-testid='signin-email']\")\n",
    "#     password = sync_get_element_by_xpath(\"//input[@data-testid='signin-password']\")\n",
    "\n",
    "#     email.send_keys(\"huohsien@gmail.com\")\n",
    "#     password.send_keys(\"jj1216\")\n",
    "\n",
    "# #     wait.until(ec.visibility_of_element_located((By.CLASS_NAME, \"button_primary__1qhjh.button__btn__2MHEg.form_primary-button__37eaW.button_standard__1p9sb\")))\n",
    "# #     sign_in_btn = driver.find_element_by_class_name(\"button_primary__1qhjh.button__btn__2MHEg.form_primary-button__37eaW.button_standard__1p9sb\") \n",
    "#     sign_in_btn = sync_get_element_by_xpath(\"//span[contains(text(), 'Sign In')]/..\")\n",
    "#     sign_in_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a notbook for scraping AI for Trading course from an old notebook called \"dlnd_course_scrape-V3.ipynb\" Rest for 2024/3/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare loop through all topics\n",
    "topic_elms = sync_get_elements_by_xpath(\"//*[@id='tree-core-curriculum']/*\")\n",
    "num_topics = len(topic_elms)\n",
    "\n",
    "# iterate each topic\n",
    "for idx_topics in range(num_topics):\n",
    "    \n",
    "    # Create topic folder\n",
    "    topic_name = ''.join(topic_elms[idx_topics].text.split('\\n')[0:2])                   \n",
    "    os.makedirs(os.path.join(root_folder, topic_name), exist_ok=True)\n",
    "    \n",
    "    debug_breakpoint(\"Topic {}\".format(topic_name), prompt_message)\n",
    "    \n",
    "    # click into a topic\n",
    "    link_topic = topic_elms[idx_topics].find_element_by_xpath(\"./a\")\n",
    "    link_topic.click()\n",
    "    \n",
    "    # Prepare loop through all lessons\n",
    "    expand_all_complete_lessons()\n",
    "    \n",
    "    lesson_elms = sync_get_elements_by_xpath(\"//div[@data-test='part-syllabus']/ol/li\")\n",
    "    num_lessons = len(lesson_elms)\n",
    "    \n",
    "    #iterate each lesson\n",
    "    for idx_lesson in range(num_lessons):\n",
    "\n",
    "        # Create lesson folder\n",
    "        lesson_elm = lesson_elms[idx_lesson]\n",
    "        lesson_name = ' - '.join(lesson_elm.text.split('\\n')[1:3])                   \n",
    "        os.makedirs(os.path.join(root_folder, topic_name,lesson_name), exist_ok=True)\n",
    "\n",
    "        debug_breakpoint(\"Lesson {}\".format(lesson_name), prompt_message)\n",
    "\n",
    "        # click into a lesson\n",
    "        link_lesson = lesson_elm.find_element_by_xpath(\"./div/div/a\")\n",
    "        link_lesson.click()\n",
    "        \n",
    "        # Prepare loop through all parts of a lesson\n",
    "        part_elms = sync_get_elements_by_xpath(\"//*[@id='tree-concepts']/ol/*\")\n",
    "        num_parts = len(part_elms)\n",
    "        \n",
    "        # iterate each part\n",
    "        for idx_part in range(num_parts):\n",
    "            \n",
    "            # Create part folder\n",
    "            part_elm = part_elms[idx_part]\n",
    "            part_name = part_elm.text\n",
    "            os.makedirs(os.path.join(root_folder, topic_name,lesson_name, part_name), exist_ok=True)\n",
    "            \n",
    "            debug_breakpoint(\"Lesson part {}\".format(part_name), prompt_message)\n",
    "            \n",
    "            # click into a part\n",
    "            link_part = part_elm.find_element_by_xpath(\"./a\")\n",
    "            link_part.click()\n",
    "            \n",
    "            # REAL CONTENTS HERE to Be STORED!\n",
    "            #\n",
    "            time.sleep(DELAY_SECONDS_CONTENT_LOADING)\n",
    "            \n",
    "            save_processed_html()\n",
    "#             debug_breakpoint(driver.current_url, prompt_message)\n",
    "            \n",
    "            # reflesh webElement after webpage reload\n",
    "            part_elms = sync_get_elements_by_xpath(\"//*[@id='tree-concepts']/ol/*\")\n",
    "\n",
    "        # go back to Lesson List\n",
    "        back_link = sync_get_element_by_xpath(\"//h3[@class='_sidebar--header--2BaH_']/a\") \n",
    "        back_link.click()\n",
    "        \n",
    "        # click open the completed lessons\n",
    "        expand_all_complete_lessons()\n",
    "        \n",
    "        # reflesh webElement after webpage reload\n",
    "        lesson_elms = sync_get_elements_by_xpath(\"//div[@data-test='part-syllabus']/ol/li\")\n",
    "\n",
    "    # reflesh webElement after webpage reload\n",
    "    topic_elms = sync_get_elements_by_xpath(\"//*[@id='tree-core-curriculum']/*\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link_topic.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand_all_complete_lessons()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element = driver.find_element_by_xpath(\"//*[h3='lesson 1']\")\n",
    "# driver.execute_script(\"return arguments[0].scrollIntoView(true);\", element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
